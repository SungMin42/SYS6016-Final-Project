{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  This is a script to use deep learning to predict stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/SYS6016-Final-Project/Code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_volume</th>\n",
       "      <th>mid_price_log</th>\n",
       "      <th>target</th>\n",
       "      <th>trade_volume_differential</th>\n",
       "      <th>mid_price_log_direction_0_1</th>\n",
       "      <th>mid_price_log_direction_0_2</th>\n",
       "      <th>mid_price_log_direction_0_3</th>\n",
       "      <th>mid_price_log_direction_0_4</th>\n",
       "      <th>mid_price_log_direction_0_5</th>\n",
       "      <th>mid_price_log_direction_0_6</th>\n",
       "      <th>trade_volume_differential_direction_0_1</th>\n",
       "      <th>trade_volume_differential_direction_0_2</th>\n",
       "      <th>trade_volume_differential_direction_0_3</th>\n",
       "      <th>trade_volume_differential_direction_0_4</th>\n",
       "      <th>trade_volume_differential_direction_0_5</th>\n",
       "      <th>trade_volume_differential_direction_0_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57599089</th>\n",
       "      <td>4659293</td>\n",
       "      <td>25.491830</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599090</th>\n",
       "      <td>4659293</td>\n",
       "      <td>25.550179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599091</th>\n",
       "      <td>4659293</td>\n",
       "      <td>25.372644</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599092</th>\n",
       "      <td>4659293</td>\n",
       "      <td>25.571578</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599093</th>\n",
       "      <td>4659293</td>\n",
       "      <td>24.424568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trade_volume  mid_price_log  target  trade_volume_differential  \\\n",
       "groupid                                                                    \n",
       "57599089       4659293      25.491830       2                        0.0   \n",
       "57599090       4659293      25.550179       0                        0.0   \n",
       "57599091       4659293      25.372644       2                        0.0   \n",
       "57599092       4659293      25.571578       0                        0.0   \n",
       "57599093       4659293      24.424568       0                        0.0   \n",
       "\n",
       "          mid_price_log_direction_0_1  mid_price_log_direction_0_2  \\\n",
       "groupid                                                              \n",
       "57599089                            2                            2   \n",
       "57599090                            2                            2   \n",
       "57599091                            0                            0   \n",
       "57599092                            2                            2   \n",
       "57599093                            0                            0   \n",
       "\n",
       "          mid_price_log_direction_0_3  mid_price_log_direction_0_4  \\\n",
       "groupid                                                              \n",
       "57599089                            2                            2   \n",
       "57599090                            2                            2   \n",
       "57599091                            0                            0   \n",
       "57599092                            2                            2   \n",
       "57599093                            0                            0   \n",
       "\n",
       "          mid_price_log_direction_0_5  mid_price_log_direction_0_6  \\\n",
       "groupid                                                              \n",
       "57599089                            2                            2   \n",
       "57599090                            2                            2   \n",
       "57599091                            0                            0   \n",
       "57599092                            2                            2   \n",
       "57599093                            0                            0   \n",
       "\n",
       "          trade_volume_differential_direction_0_1  \\\n",
       "groupid                                             \n",
       "57599089                                        1   \n",
       "57599090                                        1   \n",
       "57599091                                        1   \n",
       "57599092                                        1   \n",
       "57599093                                        1   \n",
       "\n",
       "          trade_volume_differential_direction_0_2  \\\n",
       "groupid                                             \n",
       "57599089                                        1   \n",
       "57599090                                        1   \n",
       "57599091                                        1   \n",
       "57599092                                        1   \n",
       "57599093                                        1   \n",
       "\n",
       "          trade_volume_differential_direction_0_3  \\\n",
       "groupid                                             \n",
       "57599089                                        1   \n",
       "57599090                                        1   \n",
       "57599091                                        1   \n",
       "57599092                                        1   \n",
       "57599093                                        1   \n",
       "\n",
       "          trade_volume_differential_direction_0_4  \\\n",
       "groupid                                             \n",
       "57599089                                        1   \n",
       "57599090                                        1   \n",
       "57599091                                        1   \n",
       "57599092                                        1   \n",
       "57599093                                        1   \n",
       "\n",
       "          trade_volume_differential_direction_0_5  \\\n",
       "groupid                                             \n",
       "57599089                                        1   \n",
       "57599090                                        1   \n",
       "57599091                                        1   \n",
       "57599092                                        1   \n",
       "57599093                                        1   \n",
       "\n",
       "          trade_volume_differential_direction_0_6  \n",
       "groupid                                            \n",
       "57599089                                        1  \n",
       "57599090                                        1  \n",
       "57599091                                        1  \n",
       "57599092                                        1  \n",
       "57599093                                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data (from pkl file probably)\n",
    "\n",
    "#os.getcwd()\n",
    "df = pd.read_pickle('../data/price_level_total_view_2017-01-03_AAPL_grouped_2')\n",
    "df.head()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_2d_to_3d(data, labels, window):\n",
    "    data_n, data_w = data.shape\n",
    "    stride1, stride2 = data.strides\n",
    "    new_len = data_n - window\n",
    "    data3d = as_strided(data, [new_len , window, data_w], strides=[stride1, stride1, stride2])\n",
    "#    return(data3d, labels[:len(labels)-window])\n",
    "    return(data3d, labels[window:])\n",
    "\n",
    "def flatten_3d(data):\n",
    "    data_n = data.shape[0]\n",
    "    new_width = data.shape[1]*data.shape[2]\n",
    "    \n",
    "    return np.reshape(data, (data_n, new_width)) # flesh this function out\n",
    "    \n",
    "def split_data(dfX, dfy, train_frac):\n",
    "\n",
    "   X = dfX\n",
    "   y = dfy\n",
    "   n = X.shape[0]\n",
    "   cutoff = np.floor(n * train_frac).astype(int) # total - the number you want to test, which here i'm flooring\n",
    "   #                   (amount you want in training should be 1/10th value the denominator)\n",
    "   # cutoff\n",
    "\n",
    "   X_train, X_test = (X.iloc[0:cutoff , :] , X.iloc[cutoff: , :] )\n",
    "   y_train, y_test = (y.iloc[0:cutoff].values.ravel() , y.iloc[cutoff:].values.ravel() )\n",
    "\n",
    "   ss = StandardScaler()\n",
    "   ss.fit(X_train)\n",
    "   X_train = ss.transform(X_train)\n",
    "   X_test = ss.transform(X_test)\n",
    "\n",
    "   return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(trainarray, labelarray, testarray, testlabelarray, window_size):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    train_n = trainarray.shape[0]\n",
    "    test_n = testarray.shape[0]\n",
    "    \n",
    "    #.shuffle(buffer_size=2*train_n)\n",
    "\n",
    "    with tf.name_scope(\"dataset\"):\n",
    "        training_dataset = (\n",
    "            tf.data.Dataset.from_tensor_slices(\n",
    "                (\n",
    "                    tf.cast(trainarray, tf.float32)\n",
    "                )\n",
    "            ).window(size=window_size,shift=1,stride=1,drop_remainder=False).flat_map(lambda x: x.batch(window_size))\n",
    "        )\n",
    "        \n",
    "        label_dataset = (\n",
    "            tf.data.Dataset.from_tensor_slices(\n",
    "                (\n",
    "                    tf.cast(labelarray, tf.int32)\n",
    "                )\n",
    "            ).window(size=1,shift=1,stride=1,drop_remainder=False).flat_map(lambda x: x.batch(1))\n",
    "        )\n",
    "        \n",
    "        training_dataset = tf.data.Dataset.zip((training_dataset, label_dataset))\n",
    "\n",
    "#         test_dataset = (\n",
    "#             tf.data.Dataset.from_tensor_slices(\n",
    "#                 (\n",
    "#                     tf.cast(testarray, tf.float32)#,\n",
    "# #                    tf.cast(testlabelarray, tf.int32)\n",
    "#                 )\n",
    "#             )\n",
    "#         ).shuffle(buffer_size=2*test_n).window(size=window_size,shift=1,stride=1,drop_remainder=True)#.flat_map(lambda x: x.batch(window_size))\n",
    "\n",
    "#    print(training_dataset)\n",
    "        \n",
    "    with tf.name_scope(\"iterator\"):\n",
    "        iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "        features, labels = iterator.get_next()\n",
    "        train_init = iterator.make_initializer(training_dataset) # initializer for train_data\n",
    "#         test_init = iterator.make_initializer(test_dataset) # initializer for train_data\n",
    "        test_init = None\n",
    "\n",
    "    return features, labels, train_init, test_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(features, labels, window_size, batch_size):\n",
    "    n_outputs = 3\n",
    "    \n",
    "    with tf.name_scope(\"rnn\"):\n",
    "        features = tf.reshape(shape=[-1,14,window_size], tensor=features)\n",
    "        #labels = tf.reshape(shape=[-1,1], tensor=labels)\n",
    "        rnn = tf.contrib.rnn.BasicRNNCell(num_units=window_size, name=\"RNN1\")\n",
    "        init_state = rnn.zero_state(window_size, dtype=tf.float32)\n",
    "        rnn_outputs, final_state = tf.nn.dynamic_rnn(rnn, features, initial_state=init_state)\n",
    "    \n",
    "    with tf.name_scope(\"output\"):\n",
    "        logits = tf.layers.dense(final_state, n_outputs, name=\"output\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "    # Step 5: Define the optimizer; taking as input (learning_rate) and (loss)\n",
    "    with tf.name_scope(\"train\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "        loss = tf.reduce_mean(xentropy)\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Step 6: Define the evaluation metric\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct, tf.float32))\n",
    "\n",
    "    # Step 7: Initiate\n",
    "    with tf.name_scope(\"init_and_save\"):\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "    return training_op, loss, accuracy, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns and scale data\n",
    "dfX = df.reset_index().iloc[:,5:]  #np.delete(np.arange(16), [0,2])\n",
    "dfX2 = df.reset_index().iloc[:,[2,4]]\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(dfX2)\n",
    "dfX2 = ss.transform(dfX2)\n",
    "\n",
    "dfX2 = pd.DataFrame(data=dfX2, columns= ['mid_price_log', 'trade_volume_differential'])\n",
    "dfX = pd.merge(dfX2, dfX, left_index=True, right_index=True)\n",
    "\n",
    "dfy = df.reset_index().iloc[:,3]\n",
    "\n",
    "# Create train/test sets\n",
    "trainarray,labelarray,testarray,testlabelarray = split_data(dfX, dfy, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    115967\n",
       "2     61580\n",
       "0     61298\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labelarray).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random labels if we want to test accuracy\n",
    "\n",
    "# labelarray = np.asarray([np.random.randint(0,3) for i in np.arange(labelarray.shape[0])])\n",
    "# testlabelarray = np.asarray([np.random.randint(0,3) for i in np.arange(testlabelarray.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data set to use data windows\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "window_size = 10\n",
    "# if window_size isn't even, tf.reshape throws an error down below after pooling\n",
    "#trainarray, labelarray = features_2d_to_3d(np.array(trainarray), np.array(labelarray), window_size)\n",
    "#testarray, testlabelarray = features_2d_to_3d(np.array(testarray), np.array(testlabelarray), window_size)\n",
    "#trainarray = flatten_3d(trainarray)\n",
    "#testarray = flatten_3d(testarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = trainarray.shape[0]\n",
    "test_n = testarray.shape[0]\n",
    "#height = trainarray.shape[1]\n",
    "#width = trainarray.shape[2]\n",
    "#window_size = 10\n",
    "\n",
    "batch_size = 400\n",
    "n_batches = train_n // batch_size\n",
    "n_batches_test = test_n // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainarray = np.reshape(trainarray, newshape=[-1, height, width, 1])\n",
    "#testarray = np.reshape(testarray, newshape=[-1, height, width, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create datasets & model\n",
    "\n",
    "features, labels, tr_init, te_init = create_datasets(trainarray, labelarray, testarray, testlabelarray, window_size)\n",
    "training_op, loss, accuracy, init = create_rnn_model(features, labels, window_size, batch_size)\n",
    "\n",
    "#temp = create_datasets(trainarray, labelarray, testarray, testlabelarray, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [1,14] vs. shape[1] = [10,10]\n\t [[node rnn/rnn/while/RNN1/concat (defined at <ipython-input-50-70ee87e9c7d3>:9) ]]\n\t [[node eval/Sum (defined at <ipython-input-50-70ee87e9c7d3>:25) ]]\n\nCaused by op 'rnn/rnn/while/RNN1/concat', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-56-faf5bad0b956>\", line 4, in <module>\n    training_op, loss, accuracy, init = create_rnn_model(features, labels, window_size, batch_size)\n  File \"<ipython-input-50-70ee87e9c7d3>\", line 9, in create_rnn_model\n    rnn_outputs, final_state = tf.nn.dynamic_rnn(rnn, features, initial_state=init_state)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 671, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 879, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 847, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 833, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 371, in __call__\n    *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 451, in call\n    array_ops.concat([inputs, state], 1), self._kernel)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1256, in concat\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1149, in concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,14] vs. shape[1] = [10,10]\n\t [[node rnn/rnn/while/RNN1/concat (defined at <ipython-input-50-70ee87e9c7d3>:9) ]]\n\t [[node eval/Sum (defined at <ipython-input-50-70ee87e9c7d3>:25) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [1,14] vs. shape[1] = [10,10]\n\t [[{{node rnn/rnn/while/RNN1/concat}}]]\n\t [[{{node eval/Sum}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-627cb9bc6f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# , feed_dict={keep_prob : 0.75} # for dropout only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [1,14] vs. shape[1] = [10,10]\n\t [[node rnn/rnn/while/RNN1/concat (defined at <ipython-input-50-70ee87e9c7d3>:9) ]]\n\t [[node eval/Sum (defined at <ipython-input-50-70ee87e9c7d3>:25) ]]\n\nCaused by op 'rnn/rnn/while/RNN1/concat', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-56-faf5bad0b956>\", line 4, in <module>\n    training_op, loss, accuracy, init = create_rnn_model(features, labels, window_size, batch_size)\n  File \"<ipython-input-50-70ee87e9c7d3>\", line 9, in create_rnn_model\n    rnn_outputs, final_state = tf.nn.dynamic_rnn(rnn, features, initial_state=init_state)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 671, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 879, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 847, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 833, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 371, in __call__\n    *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 451, in call\n    array_ops.concat([inputs, state], 1), self._kernel)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1256, in concat\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1149, in concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,14] vs. shape[1] = [10,10]\n\t [[node rnn/rnn/while/RNN1/concat (defined at <ipython-input-50-70ee87e9c7d3>:9) ]]\n\t [[node eval/Sum (defined at <ipython-input-50-70ee87e9c7d3>:25) ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "columns = ['t-plus', 'loss', 'accuracy', 'test_loss', 'test_accuracy']\n",
    "summaries = pd.DataFrame(np.zeros([n_epochs,5], dtype=float), columns=columns)\n",
    "run_name = 'model1'\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./\", graph=None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    writer.add_graph(sess.graph)\n",
    "    sess.run(init)\n",
    "    tot_batches_run = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(tr_init) # drawing samples from train_data\n",
    "        train_loss, train_accuracy = 0, 0\n",
    "        for i in range(n_batches):\n",
    "            try:\n",
    "                _, loss_value, acc_value = sess.run([training_op, loss, accuracy]) # , feed_dict={keep_prob : 0.75} # for dropout only\n",
    "                train_loss += loss_value\n",
    "                train_accuracy += acc_value\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"out of range on iter {}\".format(i))\n",
    "                break\n",
    "        train_accuracy = train_accuracy/(train_n)\n",
    "                \n",
    "        # Now get testing loss\n",
    "        sess.run(te_init) # drawing samples from test_data\n",
    "        test_loss, test_accuracy = 0, 0\n",
    "        for i in range(n_batches_test):\n",
    "            try:\n",
    "                loss_value, acc_value = sess.run([loss, accuracy]) # , feed_dict={keep_prob : 0.75} # for dropout only\n",
    "                test_loss += loss_value\n",
    "                test_accuracy += acc_value\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"out of range on iter {}\".format(i))\n",
    "                break\n",
    "        test_accuracy = test_accuracy/(test_n)\n",
    "        \n",
    "        \n",
    "#         epoch_time = time.time()\n",
    "        print(\"Epoch: {}, Train_Loss: {:.4f}, Test_Loss: {:.4f}, Train_Accuracy: {:.4f}, Test_Accuracy: {:.4f}\"\\\n",
    "              .format(epoch, train_loss, test_loss, train_accuracy, test_accuracy))\n",
    "#         cum_time = epoch_time - start_time\n",
    "#         summaries.iloc[epoch,:] = cum_time, train_loss, test_loss, train_accuracy, te_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
